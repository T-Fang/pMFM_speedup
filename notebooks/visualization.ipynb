{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cuda devices: 0\n",
      "My device: cpu\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "sys.path.insert(1, '../')\n",
    "import src\n",
    "\n",
    "from src.utils.init_utils import seed_all, set_gpu_device, load_dataset, load_split\n",
    "seed_all()\n",
    "gpu_number=3\n",
    "device, run_on_gpu = set_gpu_device(gpu_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = load_split('validation', use_SC=True, use_coef=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 7.0197e+00, -1.5222e+00,  4.0103e-01,  2.5643e+00,  3.5237e-01,\n",
      "         7.1930e-02,  1.7195e-03,  2.2451e-03,  7.2764e-05,  2.0611e+00])\n"
     ]
    }
   ],
   "source": [
    "print(val_ds.params[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC loaded for test 1!\n",
      "10000 param coefficients loaded for test 1!\n",
      "SC loaded for test 2!\n",
      "10000 param coefficients loaded for test 2!\n",
      "SC loaded for test 3!\n",
      "10000 param coefficients loaded for test 3!\n",
      "SC loaded for test 4!\n",
      "10000 param coefficients loaded for test 4!\n",
      "SC loaded for test 5!\n",
      "10000 param coefficients loaded for test 5!\n",
      "SC loaded for test 6!\n",
      "10000 param coefficients loaded for test 6!\n",
      "SC loaded for test 7!\n",
      "10000 param coefficients loaded for test 7!\n",
      "SC loaded for test 8!\n",
      "10000 param coefficients loaded for test 8!\n",
      "SC loaded for test 9!\n",
      "10000 param coefficients loaded for test 9!\n",
      "SC loaded for test 10!\n",
      "10000 param coefficients loaded for test 10!\n",
      "SC loaded for test 11!\n",
      "10000 param coefficients loaded for test 11!\n",
      "SC loaded for test 12!\n",
      "10000 param coefficients loaded for test 12!\n",
      "SC loaded for test 13!\n",
      "10000 param coefficients loaded for test 13!\n",
      "SC loaded for test 14!\n",
      "10000 param coefficients loaded for test 14!\n",
      "SC loaded for test 15!\n",
      "10000 param coefficients loaded for test 15!\n",
      "SC loaded for test 16!\n",
      "10000 param coefficients loaded for test 16!\n",
      "SC loaded for test 17!\n",
      "10000 param coefficients loaded for test 17!\n"
     ]
    }
   ],
   "source": [
    "test_ds = load_split('test', use_SC=True, use_coef=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC loaded for train 1!\n",
      "10000 param coefficients loaded for train 1!\n",
      "SC loaded for train 2!\n",
      "10000 param coefficients loaded for train 2!\n",
      "SC loaded for train 3!\n",
      "10000 param coefficients loaded for train 3!\n",
      "SC loaded for train 4!\n",
      "10000 param coefficients loaded for train 4!\n",
      "SC loaded for train 5!\n",
      "10000 param coefficients loaded for train 5!\n",
      "SC loaded for train 6!\n",
      "10000 param coefficients loaded for train 6!\n",
      "SC loaded for train 7!\n",
      "10000 param coefficients loaded for train 7!\n",
      "SC loaded for train 8!\n",
      "10000 param coefficients loaded for train 8!\n",
      "SC loaded for train 9!\n",
      "10000 param coefficients loaded for train 9!\n",
      "SC loaded for train 10!\n",
      "10000 param coefficients loaded for train 10!\n",
      "SC loaded for train 11!\n",
      "10000 param coefficients loaded for train 11!\n",
      "SC loaded for train 12!\n",
      "10000 param coefficients loaded for train 12!\n",
      "SC loaded for train 13!\n",
      "10000 param coefficients loaded for train 13!\n",
      "SC loaded for train 14!\n",
      "10000 param coefficients loaded for train 14!\n",
      "SC loaded for train 15!\n",
      "10000 param coefficients loaded for train 15!\n",
      "SC loaded for train 16!\n",
      "10000 param coefficients loaded for train 16!\n",
      "SC loaded for train 17!\n",
      "10000 param coefficients loaded for train 17!\n",
      "SC loaded for train 18!\n",
      "10000 param coefficients loaded for train 18!\n",
      "SC loaded for train 19!\n",
      "10000 param coefficients loaded for train 19!\n",
      "SC loaded for train 20!\n",
      "10000 param coefficients loaded for train 20!\n",
      "SC loaded for train 21!\n",
      "10000 param coefficients loaded for train 21!\n",
      "SC loaded for train 22!\n",
      "10000 param coefficients loaded for train 22!\n",
      "SC loaded for train 23!\n",
      "10000 param coefficients loaded for train 23!\n",
      "SC loaded for train 24!\n",
      "10000 param coefficients loaded for train 24!\n",
      "SC loaded for train 25!\n",
      "10000 param coefficients loaded for train 25!\n",
      "SC loaded for train 26!\n",
      "10000 param coefficients loaded for train 26!\n",
      "SC loaded for train 27!\n",
      "10000 param coefficients loaded for train 27!\n",
      "SC loaded for train 28!\n",
      "10000 param coefficients loaded for train 28!\n",
      "SC loaded for train 29!\n",
      "10000 param coefficients loaded for train 29!\n",
      "SC loaded for train 30!\n",
      "10000 param coefficients loaded for train 30!\n",
      "SC loaded for train 31!\n",
      "10000 param coefficients loaded for train 31!\n",
      "SC loaded for train 32!\n",
      "10000 param coefficients loaded for train 32!\n",
      "SC loaded for train 33!\n",
      "10000 param coefficients loaded for train 33!\n",
      "SC loaded for train 34!\n",
      "10000 param coefficients loaded for train 34!\n",
      "SC loaded for train 35!\n",
      "10000 param coefficients loaded for train 35!\n",
      "SC loaded for train 36!\n",
      "10000 param coefficients loaded for train 36!\n",
      "SC loaded for train 37!\n",
      "10000 param coefficients loaded for train 37!\n",
      "SC loaded for train 38!\n",
      "10000 param coefficients loaded for train 38!\n",
      "SC loaded for train 39!\n",
      "10000 param coefficients loaded for train 39!\n",
      "SC loaded for train 40!\n",
      "10000 param coefficients loaded for train 40!\n",
      "SC loaded for train 41!\n",
      "10000 param coefficients loaded for train 41!\n",
      "SC loaded for train 42!\n",
      "10000 param coefficients loaded for train 42!\n",
      "SC loaded for train 43!\n",
      "10000 param coefficients loaded for train 43!\n",
      "SC loaded for train 44!\n",
      "10000 param coefficients loaded for train 44!\n",
      "SC loaded for train 45!\n",
      "10000 param coefficients loaded for train 45!\n",
      "SC loaded for train 46!\n",
      "10000 param coefficients loaded for train 46!\n",
      "SC loaded for train 47!\n",
      "10000 param coefficients loaded for train 47!\n",
      "SC loaded for train 48!\n",
      "10000 param coefficients loaded for train 48!\n",
      "SC loaded for train 49!\n",
      "10000 param coefficients loaded for train 49!\n",
      "SC loaded for train 50!\n",
      "10000 param coefficients loaded for train 50!\n",
      "SC loaded for train 51!\n",
      "10000 param coefficients loaded for train 51!\n",
      "SC loaded for train 52!\n",
      "10000 param coefficients loaded for train 52!\n",
      "SC loaded for train 53!\n",
      "10000 param coefficients loaded for train 53!\n",
      "SC loaded for train 54!\n",
      "10000 param coefficients loaded for train 54!\n",
      "SC loaded for train 55!\n",
      "10000 param coefficients loaded for train 55!\n",
      "SC loaded for train 56!\n",
      "10000 param coefficients loaded for train 56!\n",
      "SC loaded for train 57!\n",
      "10000 param coefficients loaded for train 57!\n"
     ]
    }
   ],
   "source": [
    "train_ds = load_split('train', use_SC=True, use_coef=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, validation_ds, test_ds = load_dataset(use_SC=True, use_coef=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC loaded for train 1!\n",
      "10000 params loaded for train 1!\n",
      "SC loaded for train 2!\n",
      "10000 params loaded for train 2!\n",
      "SC loaded for train 3!\n",
      "10000 params loaded for train 3!\n",
      "SC loaded for train 4!\n",
      "10000 params loaded for train 4!\n",
      "SC loaded for train 5!\n",
      "10000 params loaded for train 5!\n",
      "SC loaded for train 6!\n",
      "10000 params loaded for train 6!\n",
      "SC loaded for train 7!\n",
      "10000 params loaded for train 7!\n",
      "SC loaded for train 8!\n",
      "10000 params loaded for train 8!\n",
      "SC loaded for train 9!\n",
      "10000 params loaded for train 9!\n",
      "SC loaded for train 10!\n",
      "10000 params loaded for train 10!\n",
      "SC loaded for train 11!\n",
      "10000 params loaded for train 11!\n",
      "SC loaded for train 12!\n",
      "10000 params loaded for train 12!\n",
      "SC loaded for train 13!\n",
      "10000 params loaded for train 13!\n",
      "SC loaded for train 14!\n",
      "10000 params loaded for train 14!\n",
      "SC loaded for train 15!\n",
      "10000 params loaded for train 15!\n",
      "SC loaded for train 16!\n",
      "10000 params loaded for train 16!\n",
      "SC loaded for train 17!\n",
      "10000 params loaded for train 17!\n",
      "SC loaded for train 18!\n",
      "10000 params loaded for train 18!\n",
      "SC loaded for train 19!\n",
      "10000 params loaded for train 19!\n",
      "SC loaded for train 20!\n",
      "10000 params loaded for train 20!\n",
      "SC loaded for train 21!\n",
      "10000 params loaded for train 21!\n",
      "SC loaded for train 22!\n",
      "10000 params loaded for train 22!\n",
      "SC loaded for train 23!\n",
      "10000 params loaded for train 23!\n",
      "SC loaded for train 24!\n",
      "10000 params loaded for train 24!\n",
      "SC loaded for train 25!\n",
      "10000 params loaded for train 25!\n",
      "SC loaded for train 26!\n",
      "10000 params loaded for train 26!\n",
      "SC loaded for train 27!\n",
      "10000 params loaded for train 27!\n",
      "SC loaded for train 28!\n",
      "10000 params loaded for train 28!\n",
      "SC loaded for train 29!\n",
      "10000 params loaded for train 29!\n",
      "SC loaded for train 30!\n",
      "10000 params loaded for train 30!\n",
      "SC loaded for train 31!\n",
      "10000 params loaded for train 31!\n",
      "SC loaded for train 32!\n",
      "10000 params loaded for train 32!\n",
      "SC loaded for train 33!\n",
      "10000 params loaded for train 33!\n",
      "SC loaded for train 34!\n",
      "10000 params loaded for train 34!\n",
      "SC loaded for train 35!\n",
      "10000 params loaded for train 35!\n",
      "SC loaded for train 36!\n",
      "10000 params loaded for train 36!\n",
      "SC loaded for train 37!\n",
      "10000 params loaded for train 37!\n",
      "SC loaded for train 38!\n",
      "10000 params loaded for train 38!\n",
      "SC loaded for train 39!\n",
      "10000 params loaded for train 39!\n",
      "SC loaded for train 40!\n",
      "10000 params loaded for train 40!\n",
      "SC loaded for train 41!\n",
      "10000 params loaded for train 41!\n",
      "SC loaded for train 42!\n",
      "10000 params loaded for train 42!\n",
      "SC loaded for train 43!\n",
      "10000 params loaded for train 43!\n",
      "SC loaded for train 44!\n",
      "10000 params loaded for train 44!\n",
      "SC loaded for train 45!\n",
      "10000 params loaded for train 45!\n",
      "SC loaded for train 46!\n",
      "10000 params loaded for train 46!\n",
      "SC loaded for train 47!\n",
      "10000 params loaded for train 47!\n",
      "SC loaded for train 48!\n",
      "10000 params loaded for train 48!\n",
      "SC loaded for train 49!\n",
      "10000 params loaded for train 49!\n",
      "SC loaded for train 50!\n",
      "10000 params loaded for train 50!\n",
      "SC loaded for train 51!\n",
      "10000 params loaded for train 51!\n",
      "SC loaded for train 52!\n",
      "10000 params loaded for train 52!\n",
      "SC loaded for train 53!\n",
      "10000 params loaded for train 53!\n",
      "SC loaded for train 54!\n",
      "10000 params loaded for train 54!\n",
      "SC loaded for train 55!\n",
      "10000 params loaded for train 55!\n",
      "SC loaded for train 56!\n",
      "10000 params loaded for train 56!\n",
      "SC loaded for train 57!\n",
      "10000 params loaded for train 57!\n",
      "SC loaded for validation 1!\n",
      "10000 params loaded for validation 1!\n",
      "SC loaded for validation 2!\n",
      "10000 params loaded for validation 2!\n",
      "SC loaded for validation 3!\n",
      "10000 params loaded for validation 3!\n",
      "SC loaded for validation 4!\n",
      "10000 params loaded for validation 4!\n",
      "SC loaded for validation 5!\n",
      "10000 params loaded for validation 5!\n",
      "SC loaded for validation 6!\n",
      "10000 params loaded for validation 6!\n",
      "SC loaded for validation 7!\n",
      "10000 params loaded for validation 7!\n",
      "SC loaded for validation 8!\n",
      "10000 params loaded for validation 8!\n",
      "SC loaded for validation 9!\n",
      "10000 params loaded for validation 9!\n",
      "SC loaded for validation 10!\n",
      "10000 params loaded for validation 10!\n",
      "SC loaded for validation 11!\n",
      "10000 params loaded for validation 11!\n",
      "SC loaded for validation 12!\n",
      "10000 params loaded for validation 12!\n",
      "SC loaded for validation 13!\n",
      "10000 params loaded for validation 13!\n",
      "SC loaded for validation 14!\n",
      "10000 params loaded for validation 14!\n",
      "SC loaded for test 1!\n",
      "10000 params loaded for test 1!\n",
      "SC loaded for test 2!\n",
      "10000 params loaded for test 2!\n",
      "SC loaded for test 3!\n",
      "10000 params loaded for test 3!\n",
      "SC loaded for test 4!\n",
      "10000 params loaded for test 4!\n",
      "SC loaded for test 5!\n",
      "10000 params loaded for test 5!\n",
      "SC loaded for test 6!\n",
      "10000 params loaded for test 6!\n",
      "SC loaded for test 7!\n",
      "10000 params loaded for test 7!\n",
      "SC loaded for test 8!\n",
      "10000 params loaded for test 8!\n",
      "SC loaded for test 9!\n",
      "10000 params loaded for test 9!\n",
      "SC loaded for test 10!\n",
      "10000 params loaded for test 10!\n",
      "SC loaded for test 11!\n",
      "10000 params loaded for test 11!\n",
      "SC loaded for test 12!\n",
      "10000 params loaded for test 12!\n",
      "SC loaded for test 13!\n",
      "10000 params loaded for test 13!\n",
      "SC loaded for test 14!\n",
      "10000 params loaded for test 14!\n",
      "SC loaded for test 15!\n",
      "10000 params loaded for test 15!\n",
      "SC loaded for test 16!\n",
      "10000 params loaded for test 16!\n",
      "SC loaded for test 17!\n",
      "10000 params loaded for test 17!\n"
     ]
    }
   ],
   "source": [
    "train_ds, validation_ds, test_ds = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1., 1., 1.]),\n",
       " tensor([1., 1., 1.]),\n",
       " tensor([1., 1., 1.]),\n",
       " tensor([1., 1., 1.]),\n",
       " tensor([0.5190, 0.0437, 0.8637]),\n",
       " tensor([1., 1., 1.]),\n",
       " tensor([1., 1., 1.]),\n",
       " tensor([1., 1., 1.]),\n",
       " tensor([1., 1., 1.]),\n",
       " tensor([1., 1., 1.])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.cost_vectors[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC loaded for train 1!\n",
      "10000 params loaded for train 1!\n",
      "SC loaded for train 2!\n",
      "10000 params loaded for train 2!\n",
      "SC loaded for train 3!\n",
      "10000 params loaded for train 3!\n",
      "SC loaded for train 4!\n",
      "10000 params loaded for train 4!\n",
      "SC loaded for train 5!\n",
      "10000 params loaded for train 5!\n",
      "SC loaded for train 6!\n",
      "10000 params loaded for train 6!\n",
      "SC loaded for train 7!\n",
      "10000 params loaded for train 7!\n",
      "SC loaded for train 8!\n",
      "10000 params loaded for train 8!\n",
      "SC loaded for train 9!\n",
      "10000 params loaded for train 9!\n",
      "SC loaded for train 10!\n",
      "10000 params loaded for train 10!\n",
      "SC loaded for train 11!\n",
      "10000 params loaded for train 11!\n",
      "SC loaded for train 12!\n",
      "10000 params loaded for train 12!\n",
      "SC loaded for train 13!\n",
      "10000 params loaded for train 13!\n",
      "SC loaded for train 14!\n",
      "10000 params loaded for train 14!\n",
      "SC loaded for train 15!\n",
      "10000 params loaded for train 15!\n",
      "SC loaded for train 16!\n",
      "10000 params loaded for train 16!\n",
      "SC loaded for train 17!\n",
      "10000 params loaded for train 17!\n",
      "SC loaded for train 18!\n",
      "10000 params loaded for train 18!\n",
      "SC loaded for train 19!\n",
      "10000 params loaded for train 19!\n",
      "SC loaded for train 20!\n",
      "10000 params loaded for train 20!\n",
      "SC loaded for train 21!\n",
      "10000 params loaded for train 21!\n",
      "SC loaded for train 22!\n",
      "10000 params loaded for train 22!\n",
      "SC loaded for train 23!\n",
      "10000 params loaded for train 23!\n",
      "SC loaded for train 24!\n",
      "10000 params loaded for train 24!\n",
      "SC loaded for train 25!\n",
      "10000 params loaded for train 25!\n",
      "SC loaded for train 26!\n",
      "10000 params loaded for train 26!\n",
      "SC loaded for train 27!\n",
      "10000 params loaded for train 27!\n",
      "SC loaded for train 28!\n",
      "10000 params loaded for train 28!\n",
      "SC loaded for train 29!\n",
      "10000 params loaded for train 29!\n",
      "SC loaded for train 30!\n",
      "10000 params loaded for train 30!\n",
      "SC loaded for train 31!\n",
      "10000 params loaded for train 31!\n",
      "SC loaded for train 32!\n",
      "10000 params loaded for train 32!\n",
      "SC loaded for train 33!\n",
      "10000 params loaded for train 33!\n",
      "SC loaded for train 34!\n",
      "10000 params loaded for train 34!\n",
      "SC loaded for train 35!\n",
      "10000 params loaded for train 35!\n",
      "SC loaded for train 36!\n",
      "10000 params loaded for train 36!\n",
      "SC loaded for train 37!\n",
      "10000 params loaded for train 37!\n",
      "SC loaded for train 38!\n",
      "10000 params loaded for train 38!\n",
      "SC loaded for train 39!\n",
      "10000 params loaded for train 39!\n",
      "SC loaded for train 40!\n",
      "10000 params loaded for train 40!\n",
      "SC loaded for train 41!\n",
      "10000 params loaded for train 41!\n",
      "SC loaded for train 42!\n",
      "10000 params loaded for train 42!\n",
      "SC loaded for train 43!\n",
      "10000 params loaded for train 43!\n",
      "SC loaded for train 44!\n",
      "10000 params loaded for train 44!\n",
      "SC loaded for train 45!\n",
      "10000 params loaded for train 45!\n",
      "SC loaded for train 46!\n",
      "10000 params loaded for train 46!\n",
      "SC loaded for train 47!\n",
      "10000 params loaded for train 47!\n",
      "SC loaded for train 48!\n",
      "10000 params loaded for train 48!\n",
      "SC loaded for train 49!\n",
      "10000 params loaded for train 49!\n",
      "SC loaded for train 50!\n",
      "10000 params loaded for train 50!\n",
      "SC loaded for train 51!\n",
      "10000 params loaded for train 51!\n",
      "SC loaded for train 52!\n",
      "10000 params loaded for train 52!\n",
      "SC loaded for train 53!\n",
      "10000 params loaded for train 53!\n",
      "SC loaded for train 54!\n",
      "10000 params loaded for train 54!\n",
      "SC loaded for train 55!\n",
      "10000 params loaded for train 55!\n",
      "SC loaded for train 56!\n",
      "10000 params loaded for train 56!\n",
      "SC loaded for train 57!\n",
      "10000 params loaded for train 57!\n",
      "SC loaded for validation 1!\n",
      "10000 params loaded for validation 1!\n",
      "SC loaded for validation 2!\n",
      "10000 params loaded for validation 2!\n",
      "SC loaded for validation 3!\n",
      "10000 params loaded for validation 3!\n",
      "SC loaded for validation 4!\n",
      "10000 params loaded for validation 4!\n",
      "SC loaded for validation 5!\n",
      "10000 params loaded for validation 5!\n",
      "SC loaded for validation 6!\n",
      "10000 params loaded for validation 6!\n",
      "SC loaded for validation 7!\n",
      "10000 params loaded for validation 7!\n",
      "SC loaded for validation 8!\n",
      "10000 params loaded for validation 8!\n",
      "SC loaded for validation 9!\n",
      "10000 params loaded for validation 9!\n",
      "SC loaded for validation 10!\n",
      "10000 params loaded for validation 10!\n",
      "SC loaded for validation 11!\n",
      "10000 params loaded for validation 11!\n",
      "SC loaded for validation 12!\n",
      "10000 params loaded for validation 12!\n",
      "SC loaded for validation 13!\n",
      "10000 params loaded for validation 13!\n",
      "SC loaded for validation 14!\n",
      "10000 params loaded for validation 14!\n",
      "SC loaded for test 1!\n",
      "10000 params loaded for test 1!\n",
      "SC loaded for test 2!\n",
      "10000 params loaded for test 2!\n",
      "SC loaded for test 3!\n",
      "10000 params loaded for test 3!\n",
      "SC loaded for test 4!\n",
      "10000 params loaded for test 4!\n",
      "SC loaded for test 5!\n",
      "10000 params loaded for test 5!\n",
      "SC loaded for test 6!\n",
      "10000 params loaded for test 6!\n",
      "SC loaded for test 7!\n",
      "10000 params loaded for test 7!\n",
      "SC loaded for test 8!\n",
      "10000 params loaded for test 8!\n",
      "SC loaded for test 9!\n",
      "10000 params loaded for test 9!\n",
      "SC loaded for test 10!\n",
      "10000 params loaded for test 10!\n",
      "SC loaded for test 11!\n",
      "10000 params loaded for test 11!\n",
      "SC loaded for test 12!\n",
      "10000 params loaded for test 12!\n",
      "SC loaded for test 13!\n",
      "10000 params loaded for test 13!\n",
      "SC loaded for test 14!\n",
      "10000 params loaded for test 14!\n",
      "SC loaded for test 15!\n",
      "10000 params loaded for test 15!\n",
      "SC loaded for test 16!\n",
      "10000 params loaded for test 16!\n",
      "SC loaded for test 17!\n",
      "10000 params loaded for test 17!\n"
     ]
    }
   ],
   "source": [
    "train_ds_no_SC, validation_ds_no_SC, test_ds_no_SC = load_dataset(use_SC=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SC loaded for train 1!\n",
      "10000 params loaded for train 1!\n",
      "SC loaded for train 2!\n",
      "10000 params loaded for train 2!\n",
      "SC loaded for train 3!\n",
      "10000 params loaded for train 3!\n",
      "SC loaded for train 4!\n",
      "10000 params loaded for train 4!\n",
      "SC loaded for train 5!\n",
      "10000 params loaded for train 5!\n",
      "SC loaded for train 6!\n",
      "10000 params loaded for train 6!\n",
      "SC loaded for train 7!\n",
      "10000 params loaded for train 7!\n",
      "SC loaded for train 8!\n",
      "10000 params loaded for train 8!\n",
      "SC loaded for train 9!\n",
      "10000 params loaded for train 9!\n",
      "SC loaded for train 10!\n",
      "10000 params loaded for train 10!\n",
      "SC loaded for train 11!\n",
      "10000 params loaded for train 11!\n",
      "SC loaded for train 12!\n",
      "10000 params loaded for train 12!\n",
      "SC loaded for train 13!\n",
      "10000 params loaded for train 13!\n",
      "SC loaded for train 14!\n",
      "10000 params loaded for train 14!\n",
      "SC loaded for train 15!\n",
      "10000 params loaded for train 15!\n",
      "SC loaded for train 16!\n",
      "10000 params loaded for train 16!\n",
      "SC loaded for train 17!\n",
      "10000 params loaded for train 17!\n",
      "SC loaded for train 18!\n",
      "10000 params loaded for train 18!\n",
      "SC loaded for train 19!\n",
      "10000 params loaded for train 19!\n",
      "SC loaded for train 20!\n",
      "10000 params loaded for train 20!\n",
      "SC loaded for train 21!\n",
      "10000 params loaded for train 21!\n",
      "SC loaded for train 22!\n",
      "10000 params loaded for train 22!\n",
      "SC loaded for train 23!\n",
      "10000 params loaded for train 23!\n",
      "SC loaded for train 24!\n",
      "10000 params loaded for train 24!\n",
      "SC loaded for train 25!\n",
      "10000 params loaded for train 25!\n",
      "SC loaded for train 26!\n",
      "10000 params loaded for train 26!\n",
      "SC loaded for train 27!\n",
      "10000 params loaded for train 27!\n",
      "SC loaded for train 28!\n",
      "10000 params loaded for train 28!\n",
      "SC loaded for train 29!\n",
      "10000 params loaded for train 29!\n",
      "SC loaded for train 30!\n",
      "10000 params loaded for train 30!\n",
      "SC loaded for train 31!\n",
      "10000 params loaded for train 31!\n",
      "SC loaded for train 32!\n",
      "10000 params loaded for train 32!\n",
      "SC loaded for train 33!\n",
      "10000 params loaded for train 33!\n",
      "SC loaded for train 34!\n",
      "10000 params loaded for train 34!\n",
      "SC loaded for train 35!\n",
      "10000 params loaded for train 35!\n",
      "SC loaded for train 36!\n",
      "10000 params loaded for train 36!\n",
      "SC loaded for train 37!\n",
      "10000 params loaded for train 37!\n",
      "SC loaded for train 38!\n",
      "10000 params loaded for train 38!\n",
      "SC loaded for train 39!\n",
      "10000 params loaded for train 39!\n",
      "SC loaded for train 40!\n",
      "10000 params loaded for train 40!\n",
      "SC loaded for train 41!\n",
      "10000 params loaded for train 41!\n",
      "SC loaded for train 42!\n",
      "10000 params loaded for train 42!\n",
      "SC loaded for train 43!\n",
      "10000 params loaded for train 43!\n",
      "SC loaded for train 44!\n",
      "10000 params loaded for train 44!\n",
      "SC loaded for train 45!\n",
      "10000 params loaded for train 45!\n",
      "SC loaded for train 46!\n",
      "10000 params loaded for train 46!\n",
      "SC loaded for train 47!\n",
      "10000 params loaded for train 47!\n",
      "SC loaded for train 48!\n",
      "10000 params loaded for train 48!\n",
      "SC loaded for train 49!\n",
      "10000 params loaded for train 49!\n",
      "SC loaded for train 50!\n",
      "10000 params loaded for train 50!\n",
      "SC loaded for train 51!\n",
      "10000 params loaded for train 51!\n",
      "SC loaded for train 52!\n",
      "10000 params loaded for train 52!\n",
      "SC loaded for train 53!\n",
      "10000 params loaded for train 53!\n",
      "SC loaded for train 54!\n",
      "10000 params loaded for train 54!\n",
      "SC loaded for train 55!\n",
      "10000 params loaded for train 55!\n",
      "SC loaded for train 56!\n",
      "10000 params loaded for train 56!\n",
      "SC loaded for train 57!\n",
      "10000 params loaded for train 57!\n",
      "SC loaded for validation 1!\n",
      "10000 params loaded for validation 1!\n",
      "SC loaded for validation 2!\n",
      "10000 params loaded for validation 2!\n",
      "SC loaded for validation 3!\n",
      "10000 params loaded for validation 3!\n",
      "SC loaded for validation 4!\n",
      "10000 params loaded for validation 4!\n",
      "SC loaded for validation 5!\n",
      "10000 params loaded for validation 5!\n",
      "SC loaded for validation 6!\n",
      "10000 params loaded for validation 6!\n",
      "SC loaded for validation 7!\n",
      "10000 params loaded for validation 7!\n",
      "SC loaded for validation 8!\n",
      "10000 params loaded for validation 8!\n",
      "SC loaded for validation 9!\n",
      "10000 params loaded for validation 9!\n",
      "SC loaded for validation 10!\n",
      "10000 params loaded for validation 10!\n",
      "SC loaded for validation 11!\n",
      "10000 params loaded for validation 11!\n",
      "SC loaded for validation 12!\n",
      "10000 params loaded for validation 12!\n",
      "SC loaded for validation 13!\n",
      "10000 params loaded for validation 13!\n",
      "SC loaded for validation 14!\n",
      "10000 params loaded for validation 14!\n",
      "SC loaded for test 1!\n",
      "10000 params loaded for test 1!\n",
      "SC loaded for test 2!\n",
      "10000 params loaded for test 2!\n",
      "SC loaded for test 3!\n",
      "10000 params loaded for test 3!\n",
      "SC loaded for test 4!\n",
      "10000 params loaded for test 4!\n",
      "SC loaded for test 5!\n",
      "10000 params loaded for test 5!\n",
      "SC loaded for test 6!\n",
      "10000 params loaded for test 6!\n",
      "SC loaded for test 7!\n",
      "10000 params loaded for test 7!\n",
      "SC loaded for test 8!\n",
      "10000 params loaded for test 8!\n",
      "SC loaded for test 9!\n",
      "10000 params loaded for test 9!\n",
      "SC loaded for test 10!\n",
      "10000 params loaded for test 10!\n",
      "SC loaded for test 11!\n",
      "10000 params loaded for test 11!\n",
      "SC loaded for test 12!\n",
      "10000 params loaded for test 12!\n",
      "SC loaded for test 13!\n",
      "10000 params loaded for test 13!\n",
      "SC loaded for test 14!\n",
      "10000 params loaded for test 14!\n",
      "SC loaded for test 15!\n",
      "10000 params loaded for test 15!\n",
      "SC loaded for test 16!\n",
      "10000 params loaded for test 16!\n",
      "SC loaded for test 17!\n",
      "10000 params loaded for test 17!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from src.models.gnn.gnn_param_dataset import GnnParamDataset\n",
    "gnn_train_ds, gnn_validation_ds, gnn_test_ds = GnnParamDataset('train'), GnnParamDataset('validation'), GnnParamDataset('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnn_train_ds[0].y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gnn_validation_ds.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "gnn_validation_ds._data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-08-07 00:42:05,443]\u001b[0m A new study created in memory with name: no-name-88fbba1b-c2d8-45b3-bc0f-87a87efdb070\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | loss_fn   | MSELoss    | 0     \n",
      "1 | criterion | MSELoss    | 0     \n",
      "2 | layers    | Sequential | 6.0 K \n",
      "-----------------------------------------\n",
      "6.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.0 K     Total params\n",
      "0.024     Total estimated model params size (MB)\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/optuna/trial/_trial.py:590: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-08-07 00:42:06,909]\u001b[0m Trial 0 finished with value: 0.4861696660518646 and parameters: {'num_of_naive_net_layers': 3, 'naive_net_output_dim_l0': 147, 'naive_net_output_dim_l1': 9, 'naive_net_output_dim_l2': 181}. Best is trial 0 with value: 0.4861696660518646.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | loss_fn   | MSELoss    | 0     \n",
      "1 | criterion | MSELoss    | 0     \n",
      "2 | layers    | Sequential | 9.1 K \n",
      "-----------------------------------------\n",
      "9.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "9.1 K     Total params\n",
      "0.037     Total estimated model params size (MB)\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/optuna/trial/_trial.py:590: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-08-07 00:42:08,891]\u001b[0m Trial 1 finished with value: 0.4062408208847046 and parameters: {'num_of_naive_net_layers': 5, 'naive_net_output_dim_l0': 48, 'naive_net_output_dim_l1': 94, 'naive_net_output_dim_l2': 32, 'naive_net_output_dim_l3': 13, 'naive_net_output_dim_l4': 8}. Best is trial 1 with value: 0.4062408208847046.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | loss_fn   | MSELoss    | 0     \n",
      "1 | criterion | MSELoss    | 0     \n",
      "2 | layers    | Sequential | 1.3 K \n",
      "-----------------------------------------\n",
      "1.3 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.3 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/optuna/trial/_trial.py:590: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-08-07 00:42:10,422]\u001b[0m Trial 2 finished with value: 0.6631959080696106 and parameters: {'num_of_naive_net_layers': 1, 'naive_net_output_dim_l0': 83}. Best is trial 1 with value: 0.4062408208847046.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | loss_fn   | MSELoss    | 0     \n",
      "1 | criterion | MSELoss    | 0     \n",
      "2 | layers    | Sequential | 4.0 K \n",
      "-----------------------------------------\n",
      "4.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.0 K     Total params\n",
      "0.016     Total estimated model params size (MB)\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/optuna/trial/_trial.py:590: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-08-07 00:42:12,441]\u001b[0m Trial 3 finished with value: 0.3106759190559387 and parameters: {'num_of_naive_net_layers': 5, 'naive_net_output_dim_l0': 7, 'naive_net_output_dim_l1': 153, 'naive_net_output_dim_l2': 11, 'naive_net_output_dim_l3': 21, 'naive_net_output_dim_l4': 12}. Best is trial 3 with value: 0.3106759190559387.\u001b[0m\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | loss_fn   | MSELoss    | 0     \n",
      "1 | criterion | MSELoss    | 0     \n",
      "2 | layers    | Sequential | 3.8 K \n",
      "-----------------------------------------\n",
      "3.8 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.8 K     Total params\n",
      "0.015     Total estimated model params size (MB)\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 48 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1927: PossibleUserWarning: The number of training batches (4) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "  rank_zero_warn(\n",
      "/home/ftian/storage/miniconda/envs/pMFM_speedup-torch1.8/lib/python3.8/site-packages/optuna/trial/_trial.py:590: UserWarning: The reported value is ignored because this `step` 0 is already reported.\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-08-07 00:42:14,270]\u001b[0m Trial 4 finished with value: 1.2100692987442017 and parameters: {'num_of_naive_net_layers': 7, 'naive_net_output_dim_l0': 42, 'naive_net_output_dim_l1': 46, 'naive_net_output_dim_l2': 11, 'naive_net_output_dim_l3': 12, 'naive_net_output_dim_l4': 10, 'naive_net_output_dim_l5': 14, 'naive_net_output_dim_l6': 7}. Best is trial 3 with value: 0.3106759190559387.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 5\n",
      "Best trial:\n",
      "  Trial number: 3\n",
      "  Value: 0.3106759190559387\n",
      "  Params: \n",
      "    num_of_naive_net_layers: 5\n",
      "    naive_net_output_dim_l0: 7\n",
      "    naive_net_output_dim_l1: 153\n",
      "    naive_net_output_dim_l2: 11\n",
      "    naive_net_output_dim_l3: 21\n",
      "    naive_net_output_dim_l4: 12\n"
     ]
    }
   ],
   "source": [
    "from src.models.naive_net import objective_naive_net_no_SC_use_coef\n",
    "from src.utils.training_utils import tune\n",
    "tune(objective_naive_net_no_SC_use_coef, train_ds=train_ds, validation_ds=validation_ds, n_trials=5, timeout=600, save_dir='./tmp/')\n",
    "# tune(objective_naive_net_no_SC_use_coef, n_trials=5, timeout=600, save_dir='./tmp/', use_coef=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.naive_net import objective_naive_net_no_SC\n",
    "from src.utils.training_utils import tune\n",
    "tune(objective_naive_net_no_SC, train_ds=train_ds, validation_ds=validation_ds, n_trials=5, timeout=600, save_dir='./tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.naive_net import objective_naive_net_with_SC\n",
    "tune(objective_naive_net_with_SC, train_ds=train_ds, validation_ds=validation_ds, n_trials=5, timeout=600, save_dir='./tmp/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.training_utils import tune_gnn\n",
    "from src.models.gnn.gcn import objective_gcn\n",
    "tune_gnn(objective_gcn, train_ds=gnn_train_ds, validation_ds=gnn_validation_ds, n_trials=5, timeout=3600, save_dir='./tmp/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test dataset loaded!\n"
     ]
    }
   ],
   "source": [
    "test_ds = load_split('test', use_SC=False, use_coef=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.testing.testing_lib import load_naive_net_no_SC\n",
    "model = load_naive_net_no_SC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([170000, 3])\n",
      "torch.Size([170000, 3])\n",
      "MSE loss: 0.024801483377814293\n"
     ]
    }
   ],
   "source": [
    "from src.utils.test_utils import test_model\n",
    "test_model(model, test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "NUM_WORKERS = 0\n",
    "PIN_MEMORY = True\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, \\\n",
    "                                                num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_ds, batch_size=BATCH_SIZE, shuffle=False, \\\n",
    "                                                num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.naive_net import NaiveNet\n",
    "\n",
    "naive_net = NaiveNet(use_SC_feat=False, output_dims=[5])\n",
    "print(naive_net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(training_loader)\n",
    "(SCs, params), labels = dataiter.next()\n",
    "\n",
    "SCs = SCs.to(device=device, non_blocking=True)\n",
    "params = params.to(device=device, non_blocking=True)\n",
    "print(SCs.is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 4])\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 205])\n",
      "torch.Size([256, 3])\n"
     ]
    }
   ],
   "source": [
    "sample_output = naive_net((SCs, params))\n",
    "print(sample_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pickle\n",
    "study = pickle.load(open('/home/ftian/storage/pMFM_speedup/reports/training_log/basic_models/naive_net/with_SC/study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pickle\n",
    "study = pickle.load(open('/home/ftian/storage/pMFM_speedup/reports/training_log/basic_models/naive_net/no_SC/study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import pickle\n",
    "study = pickle.load(open('/home/ftian/storage/pMFM_speedup/reports/training_log/gnn/gcn_with_mlp/study.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_trial.number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.SC_utils import show_corr_between_all_SCs\n",
    "show_corr_between_all_SCs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.basic.subject_group import SubjectGroup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pMFM_speedup-torch1.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ecec362bb2cf8d012aa325cd5cc9a803c532f741b84de8a8d27a53686a20a24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
